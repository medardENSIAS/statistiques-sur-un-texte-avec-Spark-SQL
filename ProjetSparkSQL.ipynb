{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark.sql import SparkSession, Row, SQLContext \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Statistiques sur un texte avec Spark SQL\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_load_and_processing(text_path):\n",
    "    vocabulary = sc.textFile(text_path)\\\n",
    "        .flatMap(lambda lines: lines.lower().split())\\\n",
    "        .flatMap(lambda word: word.split(\",\"))\\\n",
    "        .flatMap(lambda word: word.split(\".\"))\\\n",
    "        .flatMap(lambda word: word.split(\";\"))\\\n",
    "        .flatMap(lambda word: word.split(\"!\"))\\\n",
    "        .flatMap(lambda word: word.split(\"?\"))\\\n",
    "        .flatMap(lambda word: word.split(\"\\\"\"))\\\n",
    "        .filter(lambda word: word is not None and len(word) > 0)\\\n",
    "        .filter(lambda word: word.find('@') == -1)\\\n",
    "        .filter(lambda word: word.find('/') == -1)\\\n",
    "        .filter(lambda word: word[0] != '-')\\\n",
    "        .filter(lambda word: word[len(word)-1] != '-')\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counts_fonction(lines):\n",
    "    return lines.flatMap(lambda line: line.split(' '))\\\n",
    "        .map(lambda word: (word, 1))\\\n",
    "        .reduceByKey(lambda count1, count2: count1 + count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rdd_to_DataFrame(lines):\n",
    "    header = Row('word', 'frequence')\n",
    "    rdd = lines.map(lambda element: header(*element))\n",
    "    return spark.createDataFrame(rdd)\n",
    "\n",
    "def build_temporary_table(dataFrame):\n",
    "    dataFrame.registerTempTable('wordCountTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text_load_and_processing(\"iliad.mb.txt\")\n",
    "line = word_counts_fonction(lines)\n",
    "df = Rdd_to_DataFrame(line)\n",
    "build_temporary_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# le mot le plus long du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " le(s) mot(s) le(s) long du text \n",
      " \n",
      " brothers-in-law-for\n"
     ]
    }
   ],
   "source": [
    "result =  sqlContext.sql('SELECT * FROM wordCountTable ORDER BY length(word) DESC LIMIT 20')\n",
    "first_word = result.collect()[0].word\n",
    "max_length = len(first_word)\n",
    "print(' le(s) mot(s) le(s) long du text:')\n",
    "for element in result.collect():\n",
    "    if max_length == len(element.word):\n",
    "        print \" \"\n",
    "        print \" {}\".format(element.word)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# le mot de quatre lettres le plus fréquent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " le(s) mot(s) de quatre lettres le(s) plus fréquent\n",
      " \n",
      "with\n"
     ]
    }
   ],
   "source": [
    "result =  sqlContext.sql('SELECT * FROM wordCountTable where length(word) = 4 ORDER BY frequence DESC LIMIT 20')\n",
    "if len(result.collect()) == 0:\n",
    "    print \"le text ne contient pas de mot de quatre lettre \"\n",
    "else:\n",
    "    max_frequence = result.collect()[0].frequence\n",
    "    print(' le(s) mot(s) de quatre lettres le(s) plus fréquent')\n",
    "    for element in result.collect():\n",
    "        if max_frequence == element.frequence:\n",
    "            print \" \"\n",
    "            print element.word\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# le mot de quinze lettres le plus fréquent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " le(s) mot(s) de quatre lettres le(s) plus fréquent\n",
      " \n",
      "many-fountained\n"
     ]
    }
   ],
   "source": [
    "result =  sqlContext.sql('SELECT * FROM wordCountTable where length(word) = 15 ORDER BY frequence DESC LIMIT 20')\n",
    "if len(result.collect()) == 0:\n",
    "    print \"le text ne contient pas de mot de quatre lettre \"\n",
    "else:\n",
    "    max_frequence = result.collect()[0].frequence\n",
    "    print(' le(s) mot(s) de quatre lettres le(s) plus fréquent')\n",
    "    for element in result.collect():\n",
    "        if max_frequence == element.frequence:\n",
    "            print \" \"\n",
    "            print element.word\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
